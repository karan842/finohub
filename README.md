# FinoHub¬Æ
<img src='https://github.com/karan842/finohub/blob/master/media/FinoHub.png' height=290px width=300px></img>

- AI driven loan eligibility prediction webappüíµü§ñ

[![forthebadge made-with-python](http://ForTheBadge.com/images/badges/made-with-python.svg)](https://www.python.org/)

------------------------------------
## What is FinoHub?ü§î
FinoHub is the loan eligibility or status prediction webapp which is based on data science lifecycle. It helps and gives the idea to the people who wanted to apply for a loan.
FinoHub gives you the result of loan status such as accepted or rejected in one click, just all you need to fill your personal information in the website. FinoHub reduces the human efforts for evaluating the loan applicants for loans and also reduces the time of both loan applicants and those who are evaluating the loan applicants for loans in old-style manner. 

<img src='https://github.com/karan842/finohub/blob/master/media/cover.png' height=300px width=550px></img>

--------------------------------

## How its made?üç®
FinoHub is made by Data Science and business analytical pipeline;

*Phase 1*:
- End goal(business perspective):
1. Main goal is to automate the loan eligibility prediction with the help of predictive machine learning models.
2. To reduce the human efforts and to produce cost-effective platform for all loan applicants and the finance firm, this actually helps the finance firm and reduces their money that they are heavily spending on the employees who are working in this loan application evaluating departments.
3. Collects the data which have *binary target variable* and understands its feature meaning and importance.
4. Understands the requirement of webapp

*Phase 2*:
-  Exploring and clening the data
1. Performing exploratory data analysis and data visualization to gather and gain some useful/important informations from the raw data.
2. Analyzing the data into univariate and bivariate fashion to see the relation between different features from the data.
3. Finding some strong relatioships and importance between independent and dependent features.
4. Fining correlation between features of the data.
5. Did all these tasks with Python libraries (numpy, pandas, matplotlib, and seaborn).

*Phase 3*:
- Data cleaning and preparation
1. Encoding all ordinal, nominal, and, numerical variables into numbers(i.e. 1s or 0s or 2s or 3s)
2. Dealing with null/missing values and imputing them with mean or mode.
3. Analyzing some statisical part of the data such as Handling outiers and eliminating them.
4. Making data ready for Machine Learning lifecycle.
